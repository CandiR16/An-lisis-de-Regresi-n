###################################################################################################
############################       Continuación de MRM                #############################
###################################################################################################

## Despues que analizas graficament, se aplican pruebas para cofirmar que el modelo
## de regresión multiple si cumple con los supuestos parab aplicar estas pruebas se
## generan los valores ajustados, residuales y los estandarizados
mochil$ajustados<-fitted(modmo) # fitted  obtiene los datos ajustados del modelo modmo
mochil$resi<-residuals(modmo) # residuals obtiene los datos residuales que sean cercanos a 0
mochil$rstud<-rstudent(modmo) # para obtener la estandarizada y los errores de los residuales

############    Prueba de Normalidad    ###########
## para realizar la prueba se requiere la paqueteria lmtest
install.packages("lmtest")
require (lmtest)
ks.test (mochil$rstud, "pnorm")  #ks.test se ocupa para hacer la prueba de normalidad 
## Se plantea un aprueba de hipótesis y se espera un p-value>.05, si tenemos un p-value
## mayor a .05 no se rechaza ña Ho y se acepta que hay normalidad
## En este caso el modelo pasa la prueba de Normalidad

## La segunda prueba que se hace es la de homogeneidad de varianzas y esta prueba se realiza
## con la función bptest 
bptest(modmo, studentize = FALSE, data = mochil)  # (modelo,la prueba no tome los errores estandarizados (rstudent),Datos que vamos a usar )
## tenemos un p-value mayor a .05 por lo tanto pasa la prueba de homogeneidad varianzas

## La tercer prueba es de autocorrelación, esta prueba se llama "durbin watson"
## la función para esta prueba es dw()
dwtest(modmo, alternative="two.sided", data=mochil)
## En esta prueba hay dos formas para comprobar I) que p-value es mayor a .05 y II) el valor 
## de durbin watson (rango aceptable 1.5 a 2.5) esto es que hay independencia o no hay correlación 
### Hasta aquí podriamos confirmar que no hay correlación entre los residuos
### Con estas pruebas ya se confirma que tenemos un modelo con buen ajuste, sin embargo hay
### que revisar los casos atipicos... para revisar los casos atipicos se usa la libreria car
install.packages("car")
require(car)
outlier.test(modmo) ## muestra que casos son los atipicos
## Una vez que observamos los casos atipicos procedemos a conocer la influencia de estos 
## casos en el modelo para observar la influencia se utiliza la función influence.measures()
influ<-influence.measures(modmo)
summary(influ)
## la Primer columna nos myestra los casos que son más influyentes  que en este modelo son
## 1,2 y 10 las columnas hace referencia a dfb nos indican la influencia en los coeficientes
## del modelo, las columnas que nos presentan mayor interés son las cook.d y hat nos exponen
## con mayor claridad la influencia, el cook.d es la distancia de cook y entre más cercano
## a 1 hay mayor influencia de la observación en este caso a observaciones 10 es que tiene
## mayor distancia de cook, en esta distancia los valores mayores a 1 hay certeza de que si
## influyen en la columna de hat se asocia con las medidas de leverange que varian entre 
## 0 y 1; entre más cercano a 1 hay mayor influencia 
## Ademas de estas pruebas se hace el análisis gráfico de los casos influyeb¿ntes, para 
## este análsis tenemos la función influenceplot(), para esto se requiere la libreria car
influenceplot(modmo)
## Análisis de este gráfico se realiza con base en el tamaño de las circunferencias que 
## arroja, es decir a mayor circunferencia el cas tiene mayor influencia
## Grafica de distancia de cook se requiere la libreria faraway
install.packages("faraway")
require(faraway)
dc<-cooks.distance(modmo) #
etiqueta<-rownames(mochil) #rownames geenera que tome los nombres de la columnas automaticamente
halfnorm(dc, 3, etiqueta) # Grafica


